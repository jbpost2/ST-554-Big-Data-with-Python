{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example to show word count using spark SQL\n",
    "\n",
    "Get things set up.  On windows so I need these extra paths to be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "from pyspark.sql.functions import explode, split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data from a local source.  End up with a spark SQL data frame with one column (value) and one entry that is the text of the first chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|chapter i  treats...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chap1 = spark.read.text(\"data/chap1.txt\")\n",
    "chap1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use `split(str, regex, limit)`: Splits str around occurrences that match regex and returns an array with a length of at most limit.\n",
    "Remember we have lazy eval though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'split(value,  , -1)'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split(chap1.value, \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the result of that, we'll use `explode()`: Separates the elements of array expr into multiple rows, or the elements of map expr into multiple rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'explode(split(value,  , -1))'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explode(split(chap1.value, \" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the column name isn't great, let's create an alias for the column name so it is easier to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'explode(split(value,  , -1)) AS `word`'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explode(split(chap1.value, \" \")).alias(\"word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now we have a column object that we can select from our original `chap1` data frame.  We need to use the select method.\n",
    "([syntax and more info](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.select.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[word: string]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = explode(split(chap1.value, \" \")).alias(\"word\")\n",
    "chap1.select(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `.show()` method to actually get the data back!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|         word|\n",
      "+-------------+\n",
      "|      chapter|\n",
      "|            i|\n",
      "|             |\n",
      "|       treats|\n",
      "|           of|\n",
      "|          the|\n",
      "|        place|\n",
      "|        where|\n",
      "|       oliver|\n",
      "|        twist|\n",
      "|          was|\n",
      "|         born|\n",
      "|          and|\n",
      "|           of|\n",
      "|          the|\n",
      "|circumstances|\n",
      "|    attending|\n",
      "|          his|\n",
      "|        birth|\n",
      "|             |\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = chap1.select(col)\n",
    "words.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that was a good check to make sure we had what we wanted.  Now we want to count the number of times each word occurs.  We'll use `groupBy()` and `count()` to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[word: string, count: bigint]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.groupBy(\"word\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `.show()` to execute all the steps above and get something back!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|         word|count|\n",
      "+-------------+-----+\n",
      "|         some|    2|\n",
      "|          few|    1|\n",
      "|         hope|    1|\n",
      "|    overseers|    2|\n",
      "|   surrounded|    1|\n",
      "|    biography|    1|\n",
      "|  perspective|    1|\n",
      "|circumstances|    1|\n",
      "|  articulated|    1|\n",
      "|        among|    1|\n",
      "|          day|    1|\n",
      "|         lips|    1|\n",
      "|    appendage|    1|\n",
      "|       raised|    2|\n",
      "|      whether|    1|\n",
      "|          did|    2|\n",
      "|        space|    1|\n",
      "|    existence|    1|\n",
      "|          two|    1|\n",
      "|     instance|    1|\n",
      "|    buildings|    1|\n",
      "|    strangers|    1|\n",
      "|     occurred|    1|\n",
      "|      inmates|    1|\n",
      "|      backand|    1|\n",
      "|       within|    1|\n",
      "|       favour|    1|\n",
      "|        could|    3|\n",
      "|          him|    2|\n",
      "|       badged|    1|\n",
      "+-------------+-----+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counts = words.groupBy(\"word\").count()\n",
    "counts.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's sort it and show some of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| word|count|\n",
      "+-----+-----+\n",
      "|  the|   75|\n",
      "|     |   40|\n",
      "|   of|   35|\n",
      "|  and|   35|\n",
      "|    a|   33|\n",
      "|   to|   27|\n",
      "|   in|   22|\n",
      "|  was|   17|\n",
      "|  her|   13|\n",
      "|   it|   13|\n",
      "| that|   12|\n",
      "|  had|   12|\n",
      "| have|   12|\n",
      "|   by|   11|\n",
      "|  his|   11|\n",
      "| been|   11|\n",
      "|  she|   11|\n",
      "|   he|   11|\n",
      "|which|   10|\n",
      "|   on|   10|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counts.sort('count', ascending = False).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
